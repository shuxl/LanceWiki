好的，我们来系统讲讲损失函数（Loss Function）这个概念，以及它的常见公式和用途。

---

# 1 **一、什么是损失函数？**  

**损失函数**用于衡量模型预测值与真实值之间的差异，目的是告诉我们模型“错了多少”。

> 损失越小，说明模型越准确；损失越大，说明模型偏离实际越远。

在模型训练中，我们的目标就是**最小化损失函数**，通过不断更新参数，让模型表现更好。

---

# 2 **二、损失函数的公式（按任务分类）**

下面按任务类型分别介绍常见损失函数及其数学表达式。

---

## 2.1 **（1）回归问题常用的损失函数**
### 2.1.1 **① 均方误差（MSE：Mean Squared Error）**
用于预测连续数值（如房价、温度）

$L = \frac{1}{n} \sum_{i=1}^{n} (\hat{y}_i - y_i)^2$
- $\hat{y}_i$：模型的预测值
- $y_i$：真实值
- $n$：样本数量
特点：
- 优点：对大误差敏感，容易收敛
- 缺点：对异常值非常敏感

---

### 2.1.2 **② 平均绝对误差（MAE：Mean Absolute Error）**

$L = \frac{1}{n} \sum_{i=1}^{n} |\hat{y}_i - y_i|$
- 优点：对异常值不敏感
- 缺点：不连续可导，梯度不稳定

---

### 2.1.3 **③ Huber 损失（MSE 和 MAE 的折中）**

$L_\delta = \begin{cases} \frac{1}{2} (\hat{y}_i - y_i)^2 & \text{if } |\hat{y}_i - y_i| \leq \delta \\ \delta \cdot \left(|\hat{y}_i - y_i| - \frac{1}{2}\delta\right) & \text{otherwise} \end{cases}$

---

## 2.2 **（2）分类问题常用的损失函数**

### 2.2.1 **① 二分类：交叉熵损失（Binary Cross Entropy）**

常用于逻辑回归、二分类神经网络输出层
$L = -\left[ y \log(\hat{y}) + (1 - y) \log(1 - \hat{y}) \right]$
- $y \in \{0, 1\}$：真实标签
- $\hat{y} = \sigma(z)$：预测概率（通过 sigmoid 得到）

### 2.2.2 **举例：**

如果 y = 1，只保留第一项：
$L = -\log(\hat{y})$
如果 y = 0，只保留第二项：
$L = -\log(1 - \hat{y})$

---

### 2.2.3 **② 多分类：**

### 2.2.4 **Softmax + 多类交叉熵损失**

用于多分类神经网络输出层
$L = -\sum_{i=1}^{K} y_i \log(\hat{y}_i)$
- K：类别数
- $y_i \in \{0,1\}$：真实类别的 one-hot 向量
- $\hat{y}_i$：通过 softmax 得到的第 i 类概率

---

## 2.3 **（3）其他常见损失函数（进阶）**

|**损失函数**|**用途**|
|---|---|
|KL 散度（KL Divergence）|比较两个概率分布差异|
|对比损失（Contrastive Loss）|用于度量学习，如 Siamese 网络|
|Triplet Loss|人脸识别中拉近同类、拉远异类样本距离|
|CTC Loss|用于语音识别、OCR 中的非对齐序列标签|

---

# 3 **三、损失函数 vs 代价函数 vs 目标函数？**

有时候这些词混用，解释如下：

|**名称**|**含义**|
|---|---|
|损失函数（Loss）|单个样本的误差度量|
|代价函数（Cost）|所有样本损失的平均|
|目标函数（Objective）|总体优化目标，有时包括正则项（如 L2 惩罚项）|

---

# 4 **四、在训练中怎么用？**

1. 前向传播计算预测值 $\hat{y}$
2. 代入损失函数计算 $L$
3. 反向传播（Backpropagation）计算梯度 $\frac{\partial L}{\partial \theta}$
4. 梯度下降法更新参数 $\theta$

---

# 5 **五、总结表格**

| **任务类型** | **损失函数**                | **公式**                                               | **说明**            |
| -------- | ----------------------- | ---------------------------------------------------- | ----------------- |
| 回归       | MSE                     | $\frac{1}{n} \sum (\hat{y}_i - y_i)^2$               | 对异常值敏感            |
| 回归       | MAE                     | $L = \frac{1}{n} \sum_{i=1}^{n} \|\hat{y}_i - y_i\|$ | $\hat{y}_i - y_i$ |
| 二分类      | Binary Cross Entropy    | $-[y \log \hat{y} + (1 - y)\log(1 - \hat{y})]$       | 最常用               |
| 多分类      | Cross Entropy + Softmax | $-\sum y_i \log \hat{y}_i$                           | 输出是概率分布           |
| 特殊任务     | Triplet、CTC             | 复杂场景                                                 | 人脸识别、语音           |
