# 1 基础概念

## 1.1 什么是矩阵（Matrix）与向量（Vector）

- **矩阵（Matrix）** 是一个按照**行和列排列的数字表格**，常用于表示线性变换、系统方程、数据表格等。
    - 数学表示：$A = \begin{bmatrix} a_{11} & a_{12} & \dots \\ a_{21} & a_{22} & \dots \end{bmatrix}$
    - 在 Python 中用 `numpy.array` 实现。
- **向量（Vector）** 是一种**一维的矩阵**，可以是**行向量**或**列向量**。
    - 行向量：$[x_1, x_2, ..., x_n]$
    - 列向量：$\begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix}$

> 向量是矩阵的特例，通常用于表示一个方向、特征或者数据样本。

---

## 1.2 行列、维度（Shape）、秩（Rank）

- **行（Row）**：横向排列的元素集合，如第 $i$ 行是 $[a_{i1}, a_{i2}, ..., a_{in}]$
- **列（Column）**：纵向排列的元素集合，如第 $j$ 列是 $[a_{1j}, a_{2j}, ..., a_{mj}]$
- **维度（Shape）**：矩阵的行数和列数，用 $(m, n)$ 表示，表示 $m$ 行 $n$ 列
- **秩（Rank）**：矩阵中**线性无关行或列**的最大数目。反映了矩阵能表达的**空间维度**。
    - 举例：一个 $3 \times 3$ 矩阵，秩为 2，说明它只有两个线性独立的行/列。

---

## 1.3 特殊矩阵

| 名称                  | 定义                    | 示例                                               |
| ------------------- | --------------------- | ------------------------------------------------ |
| 零矩阵（Zero Matrix）    | 所有元素都为 0              | $\begin{bmatrix} 0 & 0 \\ 0 & 0 \end{bmatrix}$   |
| 单位矩阵（恒等矩阵 Identity） | 对角线为 1，其他为 0，类似数值中的 1 | $\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$   |
| 对角矩阵                | 只有主对角线不为 0            | $\begin{bmatrix} 2 & 0 \\ 0 & 3 \end{bmatrix}$   |
| 对称矩阵                | 转置后相等：$A = A^T$       | $\begin{bmatrix} 1 & 2 \\ 2 & 4 \end{bmatrix}$   |
| 对称正定矩阵              | 对称且所有特征值 > 0，用于优化问题   | $\begin{bmatrix} 2 & -1 \\ -1 & 2 \end{bmatrix}$ |

---

# 2 基本运算

## 2.1 矩阵加法与标量乘法
- **矩阵加法**：对应位置相加，两个矩阵需具有相同维度。
    - $A + B = \begin{bmatrix} a_{11}+b_{11} & a_{12}+b_{12} \\ a_{21}+b_{21} & a_{22}+b_{22} \end{bmatrix}$
- **标量乘法**：矩阵中每个元素都乘以该标量。
    - $3A = \begin{bmatrix} 3a_{11} & 3a_{12} \\ 3a_{21} & 3a_{22} \end{bmatrix}$

---

## 2.2 矩阵乘法

### 2.2.1 矩阵 × 向量（Ax = b）
- 条件：矩阵 $A$ 的列数必须等于向量 $x$ 的维度
- 几何意义：对向量进行线性变换
- 示例：
    ```python
    import numpy as np
    A = np.array([[1, 2], [3, 4]])
    x = np.array([5, 6])
    np.dot(A, x)  # 输出：[17, 39]
    ```

### 2.2.2 矩阵 × 矩阵

- 条件：左矩阵的**列数** = 右矩阵的**行数**
- 计算方式：第 $i$ 行 与 第 $j$ 列对应元素乘积求和。A的列 乘以 B的行 = 新的矩阵
- [120-矩阵乘法（包括高维张量）](120-矩阵乘法（包括高维张量）.md)
- 示例：
    $A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix},\quad B = \begin{bmatrix} 5 & 6 \\ 7 & 8 \end{bmatrix}$ 
    $AB = \begin{bmatrix} 1×5 + 2×7 & 1×6 + 2×8 \\ 3×5 + 4×7 & 3×6 + 4×8 \end{bmatrix} = \begin{bmatrix} 19 & 22 \\ 43 & 50 \end{bmatrix}$

---

## 2.3 转置（Transpose）

- 记号：$A^T$
- 将矩阵的行变为列，列变为行
- 示例：
    $A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix},\quad A^T = \begin{bmatrix} 1 & 3 \\ 2 & 4 \end{bmatrix}$

# 3 矩阵X向量的思考

## 3.1 **矩阵乘以向量为何是线性变换？**

---

### 3.1.1 **问题描述**

我们考虑一个矩阵 A 与一个向量 $\mathbf{x}$ 相乘的形式：
$\mathbf{y} = A \mathbf{x}$

这个运算的结果是一个新的向量 $\mathbf{y}$，它实际上是对 $\mathbf{x}$ 施加了**线性变换（linear transformation）**。

---

### 3.1.2 **几何意义**

设：
$A = \begin{bmatrix} a & b \\ c & d \end{bmatrix}, \quad \mathbf{x} = \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}$
那么：
$A \mathbf{x} = \begin{bmatrix} a & b \\ c & d \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = x_1 \begin{bmatrix} a \\ c \end{bmatrix} + x_2 \begin{bmatrix} b \\ d \end{bmatrix}$
也就是说，**结果是** A **的两列向量的线性组合**。

---

### 3.1.3 **什么是线性变换？**

一个变换 $T$ 是线性的，当且仅当它满足两个性质：
- 加法保持：$T(\mathbf{x} + \mathbf{y}) = T(\mathbf{x}) + T(\mathbf{y})$
- 数乘保持：$T(\lambda \mathbf{x}) = \lambda T(\mathbf{x})$

矩阵乘法天然满足这两个条件，因此矩阵乘向量定义了一种线性变换。

---

### 3.1.4 **示例：常见的线性变换矩阵**

| **变换类型** | **矩阵** A                                                                            | **作用效果**         |
| -------- | ----------------------------------------------------------------------------------- | ---------------- |
| 缩放       | $\begin{bmatrix} 2 & 0 \\ 0 & 2 \end{bmatrix}$                                      | 将所有向量长度变为原来的 2 倍 |
| 旋转       | $\begin{bmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{bmatrix}$ | 绕原点旋转角度 $\theta$ |
| 投影       | $\begin{bmatrix} 1 & 0 \\ 0 & 0 \end{bmatrix}$                                      | 将向量投影到 x 轴       |
| 剪切       | $\begin{bmatrix} 1 & k \\ 0 & 1 \end{bmatrix}$                                      | 沿 x 轴剪切          |


---

### 3.1.5 **应用意义**
矩阵作为线性变换在实际中有广泛用途：
- **神经网络**：每层的线性变换可用矩阵 $W \mathbf{x} + \mathbf{b}$ 表示
- **PCA 降维**：通过协方差矩阵做特征值分解，提取主成分方向
- **图像变换**：图像平移、缩放、旋转都可用矩阵完成
- **推荐系统**：用户向量 $\mathbf{u}$ 与物品向量 $\mathbf{v}$ 做内积，即矩阵乘法

---

### 3.1.6 **总结**

- 矩阵乘以向量 $A \mathbf{x}$，表示对向量进行**线性变换**
- 本质是**矩阵列向量的线性组合**
- 满足线性映射性质（加法保持、数乘保持）
- 是机器学习、图像处理、数据降维等领域的数学基础

# 4 矩阵的线性变换逻辑探讨
## 4.1 矩阵缩放
[111-矩阵缩放](111-矩阵缩放.md)

## 4.2 矩阵旋转
[112-矩阵旋转、平移与齐次坐标](112-矩阵旋转、平移与齐次坐标.md)

## 4.3 矩阵投影
## 4.4 矩阵剪切
## 4.5 矩阵平移
[112-矩阵旋转、平移与齐次坐标](112-矩阵旋转、平移与齐次坐标.md)