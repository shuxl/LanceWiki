+ 数据库核心：数据结构
+ 事务处理与分析处理
+ 列式存储
# 1 数据库核心：数据结构
## 1.1 哈希索引
### 1.1.1 哈希索引的概括
+ 假设数据存储全部采用追加文件组成，那么最简单的索引策略就是：保存内存中的hash map，把每个键一一映射到数据文件中特定的字节偏移量，这样就可以找到每个值的位置。![](img/Pasted%20image%2020240526220452.png)，图中内存中的hash map只有key-value(字节偏移量)，可以快速找到磁盘上的实际内容。
### 1.1.2 简单案例分析
如：每个键值对频繁更新（Bitcask）
> 注：一个哈希索引是存储在一个文件中的，一个文件在一个磁盘中必定会有磁盘空间用尽的极限情况（指不做任何优化的顺序写索引）。那么哈希索引是如何写的呢？
+ 将日志分解成一定大小的段，当文件达到一定大小时就关闭它，并将后续写入到新的段文件中
+ 然后将之前的段进行压缩。压缩是将顺序写造成的重复key丢弃，只流下最新的key-value的更新值。在不断压缩的过程，也可以将多个段合并在一起
+ 每个段都有自己内存哈希表
+ 查找键的值的方式是：先看最新段的hash map，如果不存在，再去之前的段找键值。由于段会进行合并，key的查找通常不需要检查很多 hash map
### 1.1.3 哈希的其它核心点
+ 键的删除
	+ 文件中追加删除记录（又称墓碑），当合并日志段时，丢弃索引中的所有已删除键的所有值
+ 奔溃恢复
	+ 内存的hash map会在数据库重启后丢失。原则上可以通过全量读索引文件来得到每个key的偏移量，但是文件过大，扫描时间很长。但是Bitcask通过将每个段的hash map单独快照在磁盘上，来替代全文件扫描后的内存重建操作。
+ 并发控制
	+ 由一个写线程来控制文件的追加
+ 为啥是追加日志，而不是更新
	+ 磁盘特性决定追加写的写入速度更快
	+ 追加写的过程中，是插入操作，并发和崩溃恢复要简单。
	+ 有合并段的逻辑兜底，可以避免数据文件出现碎片化的问题
### 1.1.4 哈希索引的局限
+ 哈希表必须全部放入内存，不适合有大量键的情况
+ key的区间查询效率不高，只能祝哥查找
