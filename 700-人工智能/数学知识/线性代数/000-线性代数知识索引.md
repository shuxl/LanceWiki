# 1 函数
+ 复合函数（函数嵌套）及其符号表示：例如 $f(g(x))$
- 多变量函数：$f(x, y)，f(x_1, x_2, \dots, x_n)$ :  [510-多变量函数](510-多变量函数.md)
-  **向量值函数与标量值函数** : [511-向量函数与标量函数](511-向量函数与标量函数.md)
    - 向量输入/输出函数（如 $f: \mathbb{R}^n \to \mathbb{R}^m$）
    - 标量函数（如损失函数 $L: \mathbb{R}^n \to \mathbb{R}$）
# 2 矩阵
#数学/线性代数/矩阵 
+ [110-矩阵的基本概念](110-矩阵的基本概念.md)
+ [200-PCA主成份分析法](200-PCA主成份分析法.md)
## 2.1 一、矩阵基础入门（目标：理解矩阵的定义与基本运算）

### 2.1.1 基础概念

- 什么是矩阵（Matrix）与向量（Vector）
- 行列、维度（Shape）、秩（Rank）
- 特殊矩阵（零矩阵、单位矩阵、对角矩阵、对称矩阵、对称正定矩阵）

### 2.1.2 基本运算

- 矩阵加法与标量乘法
- 矩阵乘法（矩阵与向量、矩阵与矩阵）
- 转置（Transpose）
- Python 实践：使用 `numpy` 实现基础操作

### 2.1.3 推荐资源

- 《线性代数及其应用》（David C. Lay）

---

## 2.2 二、矩阵的代数性质（目标：理解矩阵在代数中的运算规则和变换能力）

### 2.2.1 逆矩阵与伴随矩阵

- 可逆性条件
- 计算逆矩阵的方法（初等行变换、伴随矩阵法）
- Python：`numpy.linalg.inv()` 使用

### 2.2.2 行列式（Determinant）

- 含义与几何解释（体积变化因子）
- 计算方法（2阶、3阶展开，拉普拉斯展开）
- 行列式的性质（线性、多重性、对称性）

### 2.2.3 初等变换与秩（Row Operations）

- 初等矩阵
- 行简化阶梯形矩阵（RREF）
- Python：`scipy.linalg.lu` 做 LU 分解辅助求解

---

## 2.3 三、线性方程组与矩阵表示（目标：矩阵如何表示线性方程组）

### 2.3.1 AX = B 的矩阵形式

- 解的情况：唯一解、无解、无穷解
- 齐次与非齐次线性系统

### 2.3.2 解法

- 消元法（高斯消元）
- 矩阵求逆法
- LU 分解

---

## 2.4 四、特征值与特征向量（目标：理解矩阵的变换本质）

### 2.4.1 特征值与特征向量定义

- 几何含义：哪些方向不变
- 求解方式：|A - λI| = 0

### 2.4.2 对角化与相似变换

- 如何将矩阵对角化
- 幂方法、QR 算法简介（了解即可）

### 2.4.3 Python 实践

- `numpy.linalg.eig()`、`scipy.linalg.eig()`、SVD 分解

---

## 2.5 五、矩阵分解与实际应用（目标：掌握高阶矩阵技巧）

### 2.5.1 矩阵分解方法
- LU 分解
- QR 分解
- SVD（奇异值分解）：推荐重点掌握
### 2.5.2 应用场景
- PCA 主成分分析
- 矩阵求解大规模线性系统
- 机器学习中的线性模型、神经网络权重

---

## 2.6 六、进阶：矩阵在机器学习中的实际应用（目标：理论联系实际）

### 2.6.1 向量空间视角（补充）
- 基、维度、子空间、正交与正交化（Gram-Schmidt）
- 投影矩阵（Projection Matrix）
### 2.6.2 实战场景
- 利用矩阵推导线性回归
- 矩阵视角理解神经网络的前向传播与反向传播
- 利用 SVD 做降维与推荐系统

---

## 2.7 建议的学习顺序和配套工具

| 阶段  | 学习内容        | 推荐工具/方式             |
| --- | ----------- | ------------------- |
| 入门  | 矩阵与基本运算     | 《3Blue1Brown》、Numpy |
| 进阶  | 逆、行列式、秩     | scipy、手工计算练习        |
| 应用  | AX=B 解法、特征值 | sklearn 的 PCA       |
| 综合  | 分解与机器学习结合   | sklearn、PyTorch     |
